#  정보보호와시스템보안
## AI_Malware_Detect

-----
### 프로젝트 목표

    PE 데이터 파일이 악성파일인지 정상파일인지 판별하는 높은 정확도의 이진 분류기 모델 완성

-----
### 프로젝트 진행 단계

```
1. Feature Selection & Data Preprocessing
2. Train
3. Validation
```

-----
### PE 데이터 파일

```
PE(Portable Executable) 포맷을 따르는 파일으로, exe/dll/sys/object/FON 파일 등이 해당된다. 
이때 PE 포맷이란 마이크로소프트 윈도우 운영체제에서 실행 가능한 파일이나 object 파일의 구조를 정의한 형식이다. 
윈도우 Loader가 실행 가능한 코드를 관리하는데 필요한 정보를 캡슐화한 데이터 구조체로, 다수의 헤더와 섹션으로 구성되어 있다.
PE 포맷에는 DOS Header, DOS Header, DOS Stub, COFF Header, Optional Header, Section Table, 그리고 Section 등의 특징들을 가지고 있다.

본 프로젝트에서 PEMINER, EMBER, PESTUDIO PE 데이터 파일을 분석하고, 중요한 특징을 추출하여 전처리하는 과정을 진행한다. 
이때, 어떤 특징이 악성에 해당되는지 파악하는 것이 중요하다.
```

-----
### 입력 데이터

- PEMINER (검증데이터 / 테스트데이터 / 학습데이터).json
- EMBER (검증데이터 / 테스트데이터 / 학습데이터).json
- PESTUDIO (검증데이터 / 테스트데이터 / 학습데이터).json
- 검증데이터_정답.csv
- 학습데이터_정답.csv

-----
### LightGBM plot_importance()
```
 LightGBM은 일반적인 균형 트리 분할 방식(Level Wise)과 다르게 리프 중심 트리 분할 방식(Leaf Wise)을 이용하는 모델이다. 
 LightGBM은 속도가 빠르고, 적은 메모리를 사용하고, 카테고리형 특징의 자동 변환 및 최적 분할이 가능하다는 장점이 있다.

 지난 CSIC 2010 Dataset 프로젝트에서, LightGBM에 대해 알아보고 각각의 특징 중요도를 그래프로 시각화해보았다. 
 그래프를 통해, 어떤 특징이 모델에게 얼만큼의 영향력을 미쳤는지, 시각화해서 볼 수 있었다. 중요도를 계산하는 방법으로 
 Importance_type를 정할 수 있고, Importance_type에는 "split"과 "gain"이 있다. "split"은 모델에서 특징이 사용된 횟수이고, 
 "gain"은 노드가 특정 특징으로 분할되었을 때 얻는 성능상의 이득이다. 
 아래 왼쪽의 이미지가 "split"에 해당되고, 오른쪽 이미지가 "gain"에 해당된다. 

 본 프로젝트에서는 지난 프로젝트에서 사용했던 LightGBM의 plot_importance() 함수를 통해, 
 어떤 특징이 중요한지 시각적으로 보면서 특징 추출을 진행하고자 한다. 
```
<div>
    <img width="300px" src="https://user-images.githubusercontent.com/55417591/140703432-22536e16-8330-4ad7-87b8-3615effc990e.png"/>
    <img width="300px" src="https://user-images.githubusercontent.com/55417591/140703477-350f3973-a453-41d9-bc6d-bf82ab2b5593.png"/>
</div>

-----
### EMBER Feature Selection & Data Preprocessing

- PEMINER는 모든 데이터를 사용해야 하기 때문에, EMBER와 PESTUDIO 파일을 대상으로 진행했다.

```
 1. LightGBM의 plot_importance()를 실행하기 전에, 우선적으로 강의 시간에 배운 내용을 토대로 Label이 다른 두 데이터를 보며, 
 정적 분석을 진행했다. 모든 특징을 추가해 학습을 시키면, 시간이 오래 걸려서 비효율적이라고 판단해, 임의로 샘플링을 하는 과정을 거쳤다. 

 가장 먼저 추가한 특징은 "entropy"이다. "entropy"는 정보를 표현할 때, 필요한 bit의 개수를 나타낸다. 이 값을 통해서 값이 큰 경우, 
 랜덤성이 강하고 암호화 되어있을 가능성이 높다는 것을 알 수 있다. 그리고 두번째로 중요하게 본 "Import"를 추가했는데, 
 "import"는 동일한 api를 사용하는 파일의 특징이자 시그니처 값이다. 
 이 둘을 중점으로 Label이 다른 두 json 파일을 비교해보며 다른 양상을 보이는 feauture를 임의로 추가했다.
 학습은 EMBER의 학습데이터를 통해서 진행했고, 검증은 EMBER의 검증 데이터를 통해 진행했다. 
 총 520개의 특징을 추가했고, 정보는 아래와 같다. 이때의 Acc는 0.9312였다.
```

- Histogram, byteentropy, string-numstring, String-printables, general-size, general-vsize, import, export, header-sizeof_code, header-sizeof_headers

```
 아래 그래프를 통해 보면 각 column에 해당하는 특징들이 얼만큼 사용되었는지 Importance_type 중 "split"을 통해 알 수 있다. 
 사용률 1순위는 import, 2순위는 general-vsize, 3순위는 header의 sizeof_code이다.
```

<div>
    <img width="437" alt="2" src="https://user-images.githubusercontent.com/55417591/146235050-95f9ba14-b2fe-4e76-bb4b-ef9fe5a91980.png">
</div>

<br>

```
2. 두번째 임의의 샘플링으로 총 526개의 특징을 추가했고, 정보와 그래프는 아래와 같다. 이때의 Acc는 0.9541이었다. 
위에서와 마찬가지로 1순위는 import, 2순위는 general-vsize였고, 3순위는 header의 sizeof_code이다. 
하지만, 3순위 아래의 특징들의 양상이 달라진 것을 볼 수 있다. 이러한 양상을 추적하며, 동일한 과정을 반복했다.
```
- Histogram, byteentropy, string-numstring, avlength, String-printables, entropy, paths, urls, registry, MZ, general-size, general-vsize, import, export, header-sizeof_code, header-sizeof_headers

<div>
    <img width="444" alt="4" src="https://user-images.githubusercontent.com/55417591/146236785-0a8feffb-9be7-4a05-a075-0207008ef397.png">
</div>

<br>

```
3. 일련의 반복 과정을 통해서, 사용률을 비교해가며, 데이터의 경향성에 대해서 파악할 수 있었다. header의 sizeof_code, 
sizeof_headers말고 다른 특징을 넣으면, 정확도가 떨어졌고, numstrings, printable, entropy, register 특징을 빼면, 
정확도가 떨어졌다. 또 section 특징을 넣으면 정확도가 높아지는 것을 볼 수 있었다. 그래서 데이터를 추리면서, import, histogram, 
urls, avlength, section 5개의 특징을 선택했다. 이 5개의 특징을 전체 학습 데이터에 적용하여서 다시 plot를 보았다.
```

<div>
    <img width="439" alt="5" src="https://user-images.githubusercontent.com/55417591/146245793-ed7a366a-0e39-43e3-abfc-1d517e327c03.png">
</div>

```
 전체 데이터를 기준으로 특징 importance를 보았을 때, EMBER 데이터만을 사용했을 때보다 더 특징을 줄일 수 있었고, 
 여러 조합을 찾아보았다. 결국, import와 section, 그리고 section의 sections 중에서도 len, size, entropy, 
 size, props를 사용했을 때, 이전의 여러 Acc 값들보다 가장 높은 Acc인 0.9602가 나왔다.

 최종적으로 EMBER Parser에서는 201개의 featrue를 select했고, class 구현 코드는 아래와 같다.
```

<br>

- 구현 코드

```python
# EMBER 데이터 json 파일에서 모든 데이터 추출 - 202개
class EmberParser:

    def __init__(self, path):
        self.report = read_json(path)
        self.vector = []
    
    # general의 imports 추출
    def get_import_info(self): 
        general = self.report["general"]
        vector = [
            general['imports']
        ]
        return vector
    
    # general의 exports 추출
    # def get_export_info(self): 
    #     general = self.report["general"]
    #     vector = [
    #         general['exports']
    #     ]
    #     return vector

    # section의 수치화 된 데이터 일부 추출
    def get_section_info(self): 
        section = self.report["section"]
        vector = [
            len(section["sections"]) # section의 sections의 길이 추출
        ]
        # 30(0.9601), 40(0.9608), 45(0.9534), 60(0.9597) 등의 숫자를 넣어서
        # column의 수를 결정해보았는데, 50일 때가 가장 높은 Acc를 보였다.
        # name(파일의 확장자)과 size를 한 쌍으로 묶어서 추출
        section_sizes = [(s['name'], s['size']) for s in section["sections"]] 
        vector.extend(FeatureHasher(50, input_type="pair").transform([section_sizes]).toarray()[0]) # section_sizes_hashed
        # name과 entropy를 한 쌍으로 묶어서 추출
        section_entropy = [(s['name'], s['entropy']) for s in section["sections"]]
        vector.extend(FeatureHasher(50, input_type="pair").transform([section_entropy]).toarray()[0]) # section_entropy_hashed
        # name과 vsize를 한 쌍으로 묶어서 추출
        section_vsize = [(s['name'], s['vsize']) for s in section["sections"]]
        vector.extend(FeatureHasher(50, input_type="pair").transform([section_vsize]).toarray()[0]) # section_vsize_hashed
        # name과 entry가 같을 때, props 추출
        props = [p for s in section["sections"] for p in s['props'] if s['name'] == section['entry']]
        vector.extend(FeatureHasher(50, input_type="string").transform([props]).toarray()[0]) # props_hashed
        return vector


    def process_report(self):
        vector = []
        # vector += self.get_histogram_info()
        # vector += self.get_string_info()
        # vector += self.get_general_file_info()
        vector += self.get_import_info()
        # vector += self.get_export_info()
        vector += self.get_section_info()
        return vector
```
-----
### PESTUDIO Feature Selection & Data Preprocessing

```
1. PESTUDIO도 EMBER와 같이, 일련의 반복적인 정적 분석을 통해서, 임의의 샘플링을 진행했고, 
첫번째로, 21개의 특징을 골라보고 결과를 보았다. 21개의 특징의 정보는 아래와 같다. 
PESTUDIO는 EMBER와는 다르게 굉장히 놀라운 결과를 볼 수 있었다.
```
- overview-entropy, size, size-without-overlay, compiler-stamp,
debugger-stamp, resources-stamp, exports-stamp, version-stamp, indicators-indicator, virustotal-detection, engine,  dos-header-size, dos-stub-size, file-header-compiler-stamp, optional-header-file-checksum, directory-size, library-blacklist, import-blacklist, export, strings-bl, count

<div>
    <img width="442" alt="7" src="https://user-images.githubusercontent.com/55417591/146249988-d6b71da5-542b-40d2-91fa-384b4056456f.png">
</div>

<br>

```
 LightGBM의 plot_importance()는 max_num_features 매개변수를 통해서 최대 뽑으려고 하는 column의 수를 정할 수 있다. 
 이 그래프에서는 20개의 column을 뽑고자 했는데, 위의 그래프를 보면 알 수 있듯이, 11개의 column이 사용된 것으로 나왔다. 
 이 그래프를 통해 21개의 특징에서 11개의 특징으로 줄일 수 있었고, 그 11개의 특징들은 아래와 같다.
```

- overview-entropy, indicators-indicator, dos-header-size, dos-stub-size, optional-header-file-checksum, directory-size, library-blacklist, import-blacklist, export, strings-bl, count


```
2. EMBER와 마찬가지로, 위의 과정에서 추출된 11개의 특징을 PESTUDIO의 데이터 뿐만 아니라, 
전체 데이터로 확장해서 학습시켰을 때, 0.9602라는 가장 높은 Acc가 나왔다. 
```

```
3. 전체 데이터에서의 plot_importance() 그래프를 확인해, 11개의 특징을 더 줄일 수 있는지 확인해보았고, 
EMBER와 마찬가지로 몇 개의 조합을 만들어 정확도를 통해 분석해보았다. 전체 데이터에서의 plot_importance() 그래프는 아래와 같다.
```

<div>
    <img width="438" alt="6" src="https://user-images.githubusercontent.com/55417591/146251887-fc86549e-4065-41ef-81f8-f53a8fd3056f.png">
</div>

<br>

```
4. 11개의 특징 중에서 몇개의 조합을 만들어 비교해본 결과, 우리는 7개의 특징으로 줄일 수 있었고, 
그때 가장 높은 Acc가 0.961이며, 현재 제출된 코드의 Max Acc라고 할 수 있다. 이때, 총 7개의 특징들은 아래와 같다.
```

- strings->bl, indicator, dosheader, strings->count, libraries, Image, imports

<br>

- 구현 코드

```python
# PESTUDIO 데이터 json 파일에서 모든 데이터 추출 - 7개
class PestudioParser:
    
    def __init__(self, path):
        try:
            self.report = read_json(path)
        except FileNotFoundError:
            self.report = None
        self.vector = []

     # overview의 수치화 된 데이터 중 entropy 추출
    def get_image_info(self):
        image = self.report["image"]
        vector = [float(image["overview"]["entropy"])]
        return vector

    # incidators의 severity가 1인 비율을 추출
    def get_indicator_info(self): 
        indicators = self.report["image"]["indicators"]
        try:
            vector = [sum(1 for s in indicators["indicator"] if s["@severity"] == "1") / len(indicators["indicator"])]
        except KeyError:
            vector = [-1]
        return vector

    # dos-header의 size(크기) 추출
    def get_dosHeader_info(self):
        try:
            header = self.report["image"]["dos-header"]
            vector = [int(header["size"])]
        except KeyError:
            vector = [-1]
        return vector

    # libraries의 @blacklist가 "x"인 요소들의 비율 추출
    def get_libraries_info(self): 
        try:
            libraries = self.report["image"]["libraries"]
            if libraries == "n/a" or len(libraries) == 1:
                vector = [0]
            else:
                try:
                    vector = [sum(1 for i in libraries["library"] if i["@blacklist"] == "x") / len(libraries["library"])]
                except TypeError:
                    vector = [1 if libraries["library"]["@blacklist"] == "x" else 0]
        except:
            vector = [-1]
        return vector

    # imports의 @blacklist가 "x"인 요소들의 비율 추출
    def get_imports_info(self): 
        try:
            imports = self.report["image"]["imports"]
            if imports == "n/a" or len(imports) == 1:
                vector = [0]
            else:
                try:
                    vector = [sum(1 for i in imports["import"] if i["@blacklist"] == "x") / len(imports["import"])]
                except TypeError:
                    vector = [1 if imports["import"]["@blacklist"] == "x" else 0]
        except:
            vector = [-1]
        return vector

    # strings의 @bl, @count 추출
    def get_strings_info(self): 
        strings = self.report["image"]["strings"]
        vector = [
            float(strings["@bl"]),
            float(strings["@count"])
        ]
        return vector
    
    def process_report(self):
        vector = []

        if self.report:
            vector += self.get_image_info()
            vector += self.get_indicator_info()
            vector += self.get_dosHeader_info()
            # vector += self.get_dosStub_info()
            # vector += self.get_optionalHeader_info()
            # vector += self.get_directories_info()
            vector += self.get_libraries_info()
            vector += self.get_imports_info()
            # vector += self.get_exports_info()
            vector += self.get_strings_info()
        else: 
            # FileNotFoundError인 경우 vector에 -1 값 넣어서 추출
            vector = [-1 for _ in range(7)]
        return vector
```

-----

### Train

```
 모델은 총 8개의 모델을 실험적으로 해보았는데, 8개 중 높은 성능을 보였던 3개의 모델은 RandomForest(0.9567), DecisionTree(0.9272), 
 그리고 LGBMClassifier(0.9575)이었다. 특히 RandomForest와 LGBMClassifier를 ensemble 했을 때의 0.961로 Acc가 가장 높게 나왔다. 
 하지만 이 세 개의 모델을 모두 ensemble 했을 때는, 0.9539라는 낮아진 Acc를 볼 수 있었다.

  본 프로젝트는 특징 추출과 전처리하는 과정이 중요하다고 생각돼, 별도의 모델의 하이퍼파라미터의 조정 없이 학습을 진행했다. 
  현 모델에서 하이퍼파라미터까지 조정이 된다면 Acc가 좀 더 높아지지 않을까 예상된다.
```

<br>

- 구현 코드

```python
# 머신러닝 정의하는 함수
def load_model(**kwargs):
    if kwargs["model"] == "rf":
        return ["rf", RandomForestClassifier(random_state=kwargs["random_state"], n_jobs=4)]
    elif kwargs["model"] == "dt":
        return ["dt", DecisionTreeClassifier(random_state=kwargs["random_state"])]
    elif kwargs["model"] == "lgb":
        return ["lgb", LGBMClassifier(random_state=kwargs["random_state"])]
    elif kwargs["model"] == "svm":
        return ["svm", SVC(random_state=kwargs["random_state"], probability=True)]
    elif kwargs["model"] == "lr":
        return ["lr", LogisticRegression(random_state=kwargs["random_state"], n_jobs=-1, max_iter=30000)] # max_iter: Gradient Descent 방식을 반복할 횟수를 정하는 파라미터
    elif kwargs["model"] == "knn":
        return ["knn", KNeighborsClassifier(n_jobs=-1)]
    elif kwargs["model"] == "adaboost":
        return ["adaboost", AdaBoostClassifier(random_state=kwargs["random_state"])]
    elif kwargs["model"] == "mlp":
        return ["mlp", MLPClassifier(random_state=kwargs["random_state"])]
    else:
        print("Unsupported Algorithm")
        return None
```

```python
# 머신러닝 모델을 선택하여 학습을 진행하는 함수
# param X_train: 학습할 2차원 리스트 특징벡터
# param y_train: 학습할 1차원 리스트 레이블 벡터
# param model: 문자열, 선택할 머신러닝 알고리즘
# return: 학습된 머신러닝 모델 객체
def train(X_train, y_train, model):
    model, clf = load_model(model=model, random_state=SEED)
    clf.fit(X_train, y_train)
    return [model, clf]
```

```python
# model 여러개 학습
model_name = ["rf", "dt", "lgb", "svm", "lr", "knn", "adaboost", "mlp"]
models = []
for model in tqdm(model_name):
    model, clf = train(X, y, model)
    models.append([model, clf])
print('Finished training.')
```

```python
# ensemble 학습
models = []
for model in tqdm(["rf", "lgb"]):
    clf = train(X, y, model)
    models.append(clf)
print('Finished training.')
```

-----

### Validation

<br>

- 구현 코드

```python
# 모델 검증 함수
def evaluate(X_test, y_test, model):
    predict = model[1].predict(X_test)
    if model[0] == "rf":
        print("RandomForest 정확도 : ", model[1].score(X_test, y_test))
    elif model[0] == "dt":
        print("DecisionTree 정확도 : ", model[1].score(X_test, y_test))
    elif model[0] == "lgb":
        print("LGBM 정확도 : ", model[1].score(X_test, y_test))
    elif model[0] == "svm":
        print("SVM 정확도 : ", model[1].score(X_test, y_test))
    elif model[0] == "lr":
        print("LogisticRegression 정확도 : ", model[1].score(X_test, y_test))
    elif model[0] == "knn":
        print("KNN 정확도 : ", model[1].score(X_test, y_test))
    elif model[0] == "adaboost":
        print("AdaBoost 정확도 : ", model[1].score(X_test, y_test))
    elif model[0] == "mlp":
        print("MLP 정확도 : ", model[1].score(X_test, y_test))
```

```python
# 검증
for model in tqdm(models): 
    evaluate(valid_X, vaild_y, model)
print('Finished evaluation.')
```

```python
# ensemble 검증 함수
def ensemble_result(X, y, models):
    predicts = []
    for model in tqdm(models):
        prob = [result for _, result in model[1].predict_proba(X)]
        predicts.append(prob)
    
    predict = np.mean(predicts, axis=0)
    predict = [1 if x >= 0.5 else 0 for x in predict]
        
    print("emsemble 정확도 : ", accuracy_score(y, predict))
```

```python
# ensemble 검증
ensemble_result(valid_X, vaild_y, models)
print('Finished evaluation.')
```

-----
### Result

<br>

1. 각 모델별 학습 및 검증 정확도
``` 
    RandomForest 정확도 :  0.9567

    DecisionTree 정확도 :  0.9272

    LGBM 정확도 :  0.9575

    SVM 정확도 :  0.8269

    LogisticRegression 정확도 :  0.8417

    KNN 정확도 :  0.905

    AdaBoost 정확도 :  0.9062

    MLP 정확도 :  0.8337
```

<br>

2. 앙상블 학습 및 검증 정확도
    - RandomForest와 LGBM 모델의 조합이 정확도가 가장 높음
```
    emsemble 정확도 :  0.961
```
